{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d6ac5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = r\"C:\\Users\\valef\\Downloads\\Indicadores_municipales_sabana_DA (1).csv\"\n",
    "\n",
    "df = pd.read_csv(path, encoding='latin-1')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1f6a260c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent                  0\n",
      "nom_ent              0\n",
      "mun                  0\n",
      "clave_mun            0\n",
      "nom_mun              0\n",
      "                    ..\n",
      "pobreza_patrim_00    3\n",
      "pobreza_patrim_10    0\n",
      "gini_90              2\n",
      "gini_00              3\n",
      "gini_10              0\n",
      "Length: 139, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the count of missing values in each column\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8bbc1d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the missing values with the mean of the column\n",
    "df = df.fillna(df.mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f3844b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent                  0\n",
      "nom_ent              0\n",
      "mun                  0\n",
      "clave_mun            0\n",
      "nom_mun              0\n",
      "                    ..\n",
      "pobreza_patrim_00    0\n",
      "pobreza_patrim_10    0\n",
      "gini_90              0\n",
      "gini_00              0\n",
      "gini_10              0\n",
      "Length: 139, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the count of missing values in each column \n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "40d75848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specified columns from the DataFrame 'df'\n",
    "df = df.drop(columns = [\"nom_ent\", \"mun\", \"clave_mun\", \"nom_mun\",\"gdo_rezsoc00\", \"gdo_rezsoc05\", \"gdo_rezsoc10\",\"ent\",\"plb\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "47d9fd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\valef\\AppData\\Local\\Temp\\ipykernel_11768\\2123512895.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Conversion of target'] = (df['N_plb'] > df['pobtot_ajustada'] / 2).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Create a new column 'Conversion of target' \n",
    "# The new column contains binary values (0 or 1) based on the following condition:\n",
    "# If the number of 'N_plb' is greater than half of the population in 'pobtot_ajustada',\n",
    "# set the value to 1 (True); otherwise, set it to 0 (False).\n",
    "\n",
    "df['Conversion of target'] = (df['N_plb'] > df['pobtot_ajustada'] / 2).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "68844463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pobtot_ajustada</th>\n",
       "      <th>pobreza</th>\n",
       "      <th>pobreza_e</th>\n",
       "      <th>pobreza_m</th>\n",
       "      <th>vul_car</th>\n",
       "      <th>vul_ing</th>\n",
       "      <th>npnv</th>\n",
       "      <th>ic_rezedu</th>\n",
       "      <th>ic_asalud</th>\n",
       "      <th>ic_segsoc</th>\n",
       "      <th>...</th>\n",
       "      <th>pobreza_cap_90</th>\n",
       "      <th>pobreza_cap_00</th>\n",
       "      <th>pobreza_cap_10</th>\n",
       "      <th>pobreza_patrim_90</th>\n",
       "      <th>pobreza_patrim_00</th>\n",
       "      <th>pobreza_patrim_10</th>\n",
       "      <th>gini_90</th>\n",
       "      <th>gini_00</th>\n",
       "      <th>gini_10</th>\n",
       "      <th>Conversion of target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>794304</td>\n",
       "      <td>30.531104</td>\n",
       "      <td>2.264478</td>\n",
       "      <td>28.266627</td>\n",
       "      <td>27.983320</td>\n",
       "      <td>8.419106</td>\n",
       "      <td>33.066469</td>\n",
       "      <td>14.970553</td>\n",
       "      <td>24.034493</td>\n",
       "      <td>41.799885</td>\n",
       "      <td>...</td>\n",
       "      <td>20.4</td>\n",
       "      <td>12.7</td>\n",
       "      <td>18.474600</td>\n",
       "      <td>43.4</td>\n",
       "      <td>33.7</td>\n",
       "      <td>41.900398</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.422628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48592</td>\n",
       "      <td>67.111172</td>\n",
       "      <td>8.040704</td>\n",
       "      <td>59.070468</td>\n",
       "      <td>22.439389</td>\n",
       "      <td>5.557604</td>\n",
       "      <td>4.891835</td>\n",
       "      <td>21.222712</td>\n",
       "      <td>15.514032</td>\n",
       "      <td>78.003570</td>\n",
       "      <td>...</td>\n",
       "      <td>39.9</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.980801</td>\n",
       "      <td>64.2</td>\n",
       "      <td>48.9</td>\n",
       "      <td>59.175800</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.343879</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53104</td>\n",
       "      <td>61.360527</td>\n",
       "      <td>7.241238</td>\n",
       "      <td>54.119289</td>\n",
       "      <td>29.428583</td>\n",
       "      <td>2.921336</td>\n",
       "      <td>6.289554</td>\n",
       "      <td>27.361207</td>\n",
       "      <td>20.812551</td>\n",
       "      <td>80.051980</td>\n",
       "      <td>...</td>\n",
       "      <td>39.5</td>\n",
       "      <td>33.1</td>\n",
       "      <td>28.259199</td>\n",
       "      <td>63.9</td>\n",
       "      <td>57.9</td>\n",
       "      <td>56.504902</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.386781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14101</td>\n",
       "      <td>52.800458</td>\n",
       "      <td>4.769001</td>\n",
       "      <td>48.031458</td>\n",
       "      <td>27.128568</td>\n",
       "      <td>7.709276</td>\n",
       "      <td>12.361698</td>\n",
       "      <td>20.889023</td>\n",
       "      <td>14.071657</td>\n",
       "      <td>65.831374</td>\n",
       "      <td>...</td>\n",
       "      <td>35.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.386101</td>\n",
       "      <td>59.7</td>\n",
       "      <td>40.1</td>\n",
       "      <td>51.164501</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.344984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101379</td>\n",
       "      <td>45.338512</td>\n",
       "      <td>6.084037</td>\n",
       "      <td>39.254475</td>\n",
       "      <td>26.262912</td>\n",
       "      <td>8.279864</td>\n",
       "      <td>20.118712</td>\n",
       "      <td>20.578144</td>\n",
       "      <td>16.567818</td>\n",
       "      <td>52.616992</td>\n",
       "      <td>...</td>\n",
       "      <td>36.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>22.139999</td>\n",
       "      <td>60.6</td>\n",
       "      <td>42.2</td>\n",
       "      <td>45.703899</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.458083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2451</th>\n",
       "      <td>21016</td>\n",
       "      <td>74.848837</td>\n",
       "      <td>12.301183</td>\n",
       "      <td>62.547654</td>\n",
       "      <td>19.229856</td>\n",
       "      <td>3.177689</td>\n",
       "      <td>2.743618</td>\n",
       "      <td>27.350040</td>\n",
       "      <td>36.056322</td>\n",
       "      <td>76.550988</td>\n",
       "      <td>...</td>\n",
       "      <td>51.8</td>\n",
       "      <td>54.8</td>\n",
       "      <td>41.368999</td>\n",
       "      <td>73.5</td>\n",
       "      <td>70.9</td>\n",
       "      <td>70.859596</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.342037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>27385</td>\n",
       "      <td>65.450191</td>\n",
       "      <td>10.203506</td>\n",
       "      <td>55.246687</td>\n",
       "      <td>23.623556</td>\n",
       "      <td>5.007426</td>\n",
       "      <td>5.918827</td>\n",
       "      <td>29.914879</td>\n",
       "      <td>53.313420</td>\n",
       "      <td>74.542926</td>\n",
       "      <td>...</td>\n",
       "      <td>34.2</td>\n",
       "      <td>25.9</td>\n",
       "      <td>20.563601</td>\n",
       "      <td>57.8</td>\n",
       "      <td>44.1</td>\n",
       "      <td>46.659199</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.362527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>117528</td>\n",
       "      <td>29.541959</td>\n",
       "      <td>3.535624</td>\n",
       "      <td>26.006335</td>\n",
       "      <td>16.644262</td>\n",
       "      <td>8.828019</td>\n",
       "      <td>44.985759</td>\n",
       "      <td>11.936088</td>\n",
       "      <td>18.316528</td>\n",
       "      <td>32.666426</td>\n",
       "      <td>...</td>\n",
       "      <td>15.7</td>\n",
       "      <td>20.7</td>\n",
       "      <td>12.115300</td>\n",
       "      <td>36.6</td>\n",
       "      <td>41.8</td>\n",
       "      <td>32.302700</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.436339</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454</th>\n",
       "      <td>20456</td>\n",
       "      <td>78.374962</td>\n",
       "      <td>14.607016</td>\n",
       "      <td>63.767946</td>\n",
       "      <td>13.750759</td>\n",
       "      <td>4.440331</td>\n",
       "      <td>3.433948</td>\n",
       "      <td>26.649950</td>\n",
       "      <td>11.769479</td>\n",
       "      <td>83.235286</td>\n",
       "      <td>...</td>\n",
       "      <td>36.2</td>\n",
       "      <td>36.4</td>\n",
       "      <td>30.037100</td>\n",
       "      <td>60.5</td>\n",
       "      <td>54.7</td>\n",
       "      <td>57.394501</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.365307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>2772</td>\n",
       "      <td>62.204207</td>\n",
       "      <td>10.102023</td>\n",
       "      <td>52.102184</td>\n",
       "      <td>27.489635</td>\n",
       "      <td>2.308246</td>\n",
       "      <td>7.997912</td>\n",
       "      <td>28.429677</td>\n",
       "      <td>44.800160</td>\n",
       "      <td>76.211864</td>\n",
       "      <td>...</td>\n",
       "      <td>37.6</td>\n",
       "      <td>44.8</td>\n",
       "      <td>26.998899</td>\n",
       "      <td>61.2</td>\n",
       "      <td>63.9</td>\n",
       "      <td>54.116299</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.385067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2456 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pobtot_ajustada    pobreza  pobreza_e  pobreza_m    vul_car   vul_ing  \\\n",
       "0              794304  30.531104   2.264478  28.266627  27.983320  8.419106   \n",
       "1               48592  67.111172   8.040704  59.070468  22.439389  5.557604   \n",
       "2               53104  61.360527   7.241238  54.119289  29.428583  2.921336   \n",
       "3               14101  52.800458   4.769001  48.031458  27.128568  7.709276   \n",
       "4              101379  45.338512   6.084037  39.254475  26.262912  8.279864   \n",
       "...               ...        ...        ...        ...        ...       ...   \n",
       "2451            21016  74.848837  12.301183  62.547654  19.229856  3.177689   \n",
       "2452            27385  65.450191  10.203506  55.246687  23.623556  5.007426   \n",
       "2453           117528  29.541959   3.535624  26.006335  16.644262  8.828019   \n",
       "2454            20456  78.374962  14.607016  63.767946  13.750759  4.440331   \n",
       "2455             2772  62.204207  10.102023  52.102184  27.489635  2.308246   \n",
       "\n",
       "           npnv  ic_rezedu  ic_asalud  ic_segsoc  ...  pobreza_cap_90  \\\n",
       "0     33.066469  14.970553  24.034493  41.799885  ...            20.4   \n",
       "1      4.891835  21.222712  15.514032  78.003570  ...            39.9   \n",
       "2      6.289554  27.361207  20.812551  80.051980  ...            39.5   \n",
       "3     12.361698  20.889023  14.071657  65.831374  ...            35.2   \n",
       "4     20.118712  20.578144  16.567818  52.616992  ...            36.6   \n",
       "...         ...        ...        ...        ...  ...             ...   \n",
       "2451   2.743618  27.350040  36.056322  76.550988  ...            51.8   \n",
       "2452   5.918827  29.914879  53.313420  74.542926  ...            34.2   \n",
       "2453  44.985759  11.936088  18.316528  32.666426  ...            15.7   \n",
       "2454   3.433948  26.649950  11.769479  83.235286  ...            36.2   \n",
       "2455   7.997912  28.429677  44.800160  76.211864  ...            37.6   \n",
       "\n",
       "      pobreza_cap_00  pobreza_cap_10  pobreza_patrim_90  pobreza_patrim_00  \\\n",
       "0               12.7       18.474600               43.4               33.7   \n",
       "1               29.0       30.980801               64.2               48.9   \n",
       "2               33.1       28.259199               63.9               57.9   \n",
       "3               21.0       22.386101               59.7               40.1   \n",
       "4               22.6       22.139999               60.6               42.2   \n",
       "...              ...             ...                ...                ...   \n",
       "2451            54.8       41.368999               73.5               70.9   \n",
       "2452            25.9       20.563601               57.8               44.1   \n",
       "2453            20.7       12.115300               36.6               41.8   \n",
       "2454            36.4       30.037100               60.5               54.7   \n",
       "2455            44.8       26.998899               61.2               63.9   \n",
       "\n",
       "      pobreza_patrim_10  gini_90  gini_00   gini_10  Conversion of target  \n",
       "0             41.900398    0.473    0.425  0.422628                     0  \n",
       "1             59.175800    0.379    0.533  0.343879                     1  \n",
       "2             56.504902    0.414    0.465  0.386781                     1  \n",
       "3             51.164501    0.392    0.541  0.344984                     1  \n",
       "4             45.703899    0.391    0.469  0.458083                     1  \n",
       "...                 ...      ...      ...       ...                   ...  \n",
       "2451          70.859596    0.403    0.589  0.342037                     1  \n",
       "2452          46.659199    0.422    0.463  0.362527                     1  \n",
       "2453          32.302700    0.528    0.498  0.436339                     0  \n",
       "2454          57.394501    0.380    0.483  0.365307                     1  \n",
       "2455          54.116299    0.431    0.500  0.385067                     1  \n",
       "\n",
       "[2456 rows x 131 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6972c",
   "metadata": {},
   "source": [
    "# KNN NO LIBRARIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e5cb3",
   "metadata": {},
   "source": [
    "The code first sets a random seed for reproducibility and shuffles the DataFrame 'df' by randomly sampling the entire dataset. This shuffling ensures data is not ordered in a specific way, avoiding potential bias during training. Subsequently, the data is split into training (80%) and testing (20%) sets. Features (X_train and X_test) are separated from labels (y_train and y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0e963044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# Divide dataset\n",
    "train_size = int(0.8 * len(df))\n",
    "train_set = df[:train_size]\n",
    "test_set = df[train_size:]\n",
    "\n",
    "# Separation\n",
    "X_train = train_set.iloc[:, :-1].values\n",
    "y_train = train_set.iloc[:, -1].values\n",
    "X_test = test_set.iloc[:, :-1].values\n",
    "y_test = test_set.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43da5df0",
   "metadata": {},
   "source": [
    "The mean is calculated for X_train along the feature dimensions (axis=0), and the standard deviation is determined in a similar manner. Subsequently, the data is standardized by subtracting the mean and dividing by the standard deviation. This standardization process is applied to both the training data (X_train) and the test data (X_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4eb60c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and standar deviation\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "\n",
    "# Normalization of data\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39e507",
   "metadata": {},
   "source": [
    "The KNN function predicts using input features and labels. It calculates distances between each test point and all training data points, considering the Euclidean distance metric. The 'k' nearest neighbors are selected by sorting these distances. The prediction for a test point results from a majority vote among these k-nearest labels. The code then computes accuracy by comparing predicted labels (y_pred) to actual test labels (y_test) and prints the accuracy as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "bb88e068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 96.54%\n"
     ]
    }
   ],
   "source": [
    "# Definir la función KNN\n",
    "def knn(X_train, y_train, X_test, k):\n",
    "    y_pred = []\n",
    "    for test_point in X_test:\n",
    "        distances = np.sqrt(np.sum((X_train - test_point) ** 2, axis=1))\n",
    "        k_indices = np.argsort(distances)[:k]\n",
    "        k_nearest_labels = y_train[k_indices]\n",
    "        pred = np.bincount(k_nearest_labels).argmax()\n",
    "        y_pred.append(pred)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Calcular la precisión\n",
    "y_pred = knn(X_train, y_train, X_test, k=4)\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "print(f\"Precisión: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec3c815",
   "metadata": {},
   "source": [
    "# PERCEPTRON NO LIBRARIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fed9ca",
   "metadata": {},
   "source": [
    "The code initializes the weights and bias for the Perceptron model. It assumes the presence of a DataFrame 'df' with features and labels, separating these into 'X' and 'y'. The Perceptron's 'step function' is defined for activation. The weights are randomly initialized using a specified random seed, with the bias set to a random value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "db825611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Separation of features and labels\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Define the activation function of perceptron)\n",
    "def step_function(z):\n",
    "    return np.where(z >= 0, 1, 0)\n",
    "\n",
    "# Initialize the weights and bias in a random form \n",
    "np.random.seed(0)\n",
    "weights = np.random.rand(X.shape[1])  \n",
    "bias = np.random.rand()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3667a",
   "metadata": {},
   "source": [
    "The code sets a learning rate of 0.1 and runs the Perceptron training for 100 epochs. It calculates the weighted sum ('z') from the dot product of 'X' and weights plus bias, applies the 'step function' for predictions, computes the error (y - predicted), and updates weights and bias scaled by the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "dc4fb189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set learning rate\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Define epochs\n",
    "epochs = 100\n",
    "\n",
    "# Train perceptron\n",
    "for epoch in range(epochs):\n",
    "    # Calculate the weighted sum plus bias (z)\n",
    "    z = np.dot(X, weights) + bias\n",
    "\n",
    "    # Apply the activation function\n",
    "    predicted = step_function(z)\n",
    "\n",
    "    # Calculate the error\n",
    "    error = y - predicted\n",
    "\n",
    "    # Update the weights and bias\n",
    "    weights += learning_rate * np.dot(X.T, error)\n",
    "    bias += learning_rate * np.sum(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1d4a86",
   "metadata": {},
   "source": [
    "Predictions are derived by applying the 'step function' to the weighted sum, computed as the dot product of feature matrix 'X' and the weight vector with added bias. The code assesses accuracy by comparing these predictions to actual labels (y), computing mean accuracy as a percentage, and printing the result to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0ca5dfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 95.36%\n"
     ]
    }
   ],
   "source": [
    "# Develop predictiona\n",
    "predictions = step_function(np.dot(X, weights) + bias)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = np.mean(predictions == y) * 100\n",
    "print(f\"Precisión: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be62b0d2",
   "metadata": {},
   "source": [
    "# PERCEPTRON "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d6d2b4",
   "metadata": {},
   "source": [
    "This code utilizes scikit-learn to train a Perceptron classifier for a binary classification task. It begins by separating features and labels, splitting the data into training and testing sets. The Perceptron model is then trained with specified parameters, and predictions are made on the test data. The code computes and displays the accuracy of the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a7c9e6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 96.54%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a Perceptron classifier\n",
    "perceptron = Perceptron(max_iter=1000, eta0=0.1, random_state=0)\n",
    "\n",
    "# Train the Perceptron on the training set\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Calculate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd9587",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4377fa",
   "metadata": {},
   "source": [
    "\n",
    "This code uses the K-Nearest Neighbors (KNN) algorithm from scikit-learn to classify data. It begins by separating features (X) and labels (y) from a DataFrame 'df' and splitting the data into training and testing sets. A KNN classifier is created with two nearest neighbors and trained on the training data. Predictions are made on the test data, and the code calculates and prints the accuracy score, indicating how well the model predicts the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b5df480b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 93.90%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a k-NN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2)  \n",
    "\n",
    "# Train the k-NN model on the training set\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión: {accuracy * 100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
